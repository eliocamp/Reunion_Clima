{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This script takes a initial date and final date and downloads the files needed to compute the wave activity flux (WAF)\n",
    "#for that given period. NCEP/NCAR Reanalysis (Kalnay etal 1996)are used \n",
    "\n",
    "#libraries needed\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "def clean():   #clean enviroment\n",
    "    import os\n",
    "    os.system(\"rm -f /tmp/*.gz /tmp/*.nc\")\n",
    "    \n",
    "def descarga_nc( mesi, diai, mesf, diaf, aniof, variable_entrada, variable_salida, tipo):\n",
    "    #tipo controla que dato bajo: 2: para anomalia 3 para climatologia\n",
    "    # Open NCEP NCAR to access to lik to data\n",
    "\n",
    "        url = 'http://www.esrl.noaa.gov/psd/cgi-bin/data/composites/comp.day.pl?var='+variable_entrada+'&level=250mb&iy[1]=&im[1]=&id[1]=&iy[2]=&im[2]=&id[2]=&iy[3]=&im[3]=&id[3]=&iy[4]=&im[4]=&id[4]=&iy[5]=&im[5]=&id[5]=&iy[6]=&im[6]=&id[6]=&iy[7]=&im[7]=&id[7]=&iy[8]=&im[8]=&id[8]=&iy[9]=&im[9]=&id[9]=&iy[10]=&im[10]=&id[10]=&iy[11]=&im[11]=&id[11]=&iy[12]=&im[12]=&id[12]=&iy[13]=&im[13]=&id[13]=&iy[14]=&im[14]=&id[14]=&iy[15]=&im[15]=&id[15]=&iy[16]=&im[16]=&id[16]=&iy[17]=&im[17]=&id[17]=&iy[18]=&im[18]=&id[18]=&iy[19]=&im[19]=&id[19]=&iy[20]=&im[20]=&id[20]=&monr1='+str(mesi)+'&dayr1='+str(diai)+'&monr2='+str(mesf)+'&dayr2='+str(diaf)+'&iyr[1]='+str(aniof)+'&filenamein=&plotlabel=&lag=0&labelc=Color&labels=Shaded&type='+str(tipo)+'&scale=&label=0&cint=&lowr=&highr=&istate=0&proj=ALL&xlat1=&xlat2=&xlon1=&xlon2=&custproj=Cylindrical+Equidistant&level1=1000mb&level2=10mb&Submit=Create+Plot'\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = response.read()      # a `bytes` object\n",
    "\n",
    "        soup = BeautifulSoup(data,'html.parser') #como es un xml, beautifull tiene un modulo de eso\n",
    "        link = soup.findAll('img')[-1]['src']\n",
    "        #Esta es una manera en que podemos obtener el link del .nc que tiene los datos del grafico\n",
    "\n",
    "        link=list(link)\n",
    "        link[-3]='n'\n",
    "        link[-2]='c'\n",
    "        link[-1]=''\n",
    "        \n",
    "        #get nc file save as netcdf\n",
    "        ruta = \"./tmp/\"\n",
    "        urllib.request.urlretrieve('http://www.esrl.noaa.gov'+\"\".join(link), ruta+variable_salida+'.nc')\n",
    "    \n",
    "        \n",
    "\n",
    "clean()\n",
    "#initial date\n",
    "\n",
    "iniy = 2016\n",
    "inim = 8\n",
    "inid = 1\n",
    "\n",
    "#final date\n",
    "finy = 2016\n",
    "finm = 8\n",
    "find = 10\n",
    "#download: geopotential height, u and v climatology for the selected period\n",
    "#          geopotential height anomalies\n",
    "\n",
    "variables = ['Zonal+Wind','Meridional+Wind','Geopotential+Height']\n",
    "\n",
    "out_var = ['zonalw_climo','meridw_climo','hgt_climo','hgt']\n",
    "\n",
    "for i in range(0,3):\n",
    "    if i==2: # download climo and anomaly for geopotential\n",
    "        descarga_nc(inim,inid,finm,find,finy,variables[i],out_var[i],3)\n",
    "        descarga_nc(inim,inid,finm,find,finy,variables[i],out_var[i+1],2)\n",
    "    descarga_nc(inim,inid,finm,find,finy,variables[i],out_var[i],3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
