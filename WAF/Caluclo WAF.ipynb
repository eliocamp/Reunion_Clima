{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#This script takes a initial date and final date and downloads the files needed to compute the wave activity flux (WAF)\n",
    "#for that given period. NCEP/NCAR Reanalysis (Kalnay etal 1996)are used \n",
    "\n",
    "#libraries needed\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "\n",
    "def clean():   #clean enviroment\n",
    "    import os\n",
    "    os.system(\"rm -f /tmp/*.gz /tmp/*.nc\")\n",
    "    \n",
    "def descarga_nc( mesi, diai, mesf, diaf, aniof, variable_entrada, variable_salida, tipo):\n",
    "    #tipo controla que dato bajo: 2: para anomalia 3 para climatologia\n",
    "    # Open NCEP NCAR to access to lik to data\n",
    "\n",
    "        url = 'http://www.esrl.noaa.gov/psd/cgi-bin/data/composites/comp.day.pl?var='+variable_entrada+'&level=250mb&iy[1]=&im[1]=&id[1]=&iy[2]=&im[2]=&id[2]=&iy[3]=&im[3]=&id[3]=&iy[4]=&im[4]=&id[4]=&iy[5]=&im[5]=&id[5]=&iy[6]=&im[6]=&id[6]=&iy[7]=&im[7]=&id[7]=&iy[8]=&im[8]=&id[8]=&iy[9]=&im[9]=&id[9]=&iy[10]=&im[10]=&id[10]=&iy[11]=&im[11]=&id[11]=&iy[12]=&im[12]=&id[12]=&iy[13]=&im[13]=&id[13]=&iy[14]=&im[14]=&id[14]=&iy[15]=&im[15]=&id[15]=&iy[16]=&im[16]=&id[16]=&iy[17]=&im[17]=&id[17]=&iy[18]=&im[18]=&id[18]=&iy[19]=&im[19]=&id[19]=&iy[20]=&im[20]=&id[20]=&monr1='+str(mesi)+'&dayr1='+str(diai)+'&monr2='+str(mesf)+'&dayr2='+str(diaf)+'&iyr[1]='+str(aniof)+'&filenamein=&plotlabel=&lag=0&labelc=Color&labels=Shaded&type='+str(tipo)+'&scale=&label=0&cint=&lowr=&highr=&istate=0&proj=ALL&xlat1=&xlat2=&xlon1=&xlon2=&custproj=Cylindrical+Equidistant&level1=1000mb&level2=10mb&Submit=Create+Plot'\n",
    "        response = urllib.request.urlopen(url)\n",
    "        data = response.read()      # a `bytes` object\n",
    "\n",
    "        soup = BeautifulSoup(data,'html.parser') #como es un xml, beautifull tiene un modulo de eso\n",
    "        link = soup.findAll('img')[-1]['src']\n",
    "        #Esta es una manera en que podemos obtener el link del .nc que tiene los datos del grafico\n",
    "\n",
    "        link=list(link)\n",
    "        link[-3]='n'\n",
    "        link[-2]='c'\n",
    "        link[-1]=''\n",
    "        \n",
    "        #get nc file save as netcdf\n",
    "        ruta = \"./tmp/\"\n",
    "        urllib.request.urlretrieve('http://www.esrl.noaa.gov'+\"\".join(link), ruta+variable_salida+'.nc')\n",
    "    \n",
    "        \n",
    "\n",
    "clean()\n",
    "#initial date\n",
    "\n",
    "iniy = 2016\n",
    "inim = 8\n",
    "inid = 1\n",
    "\n",
    "#final date\n",
    "finy = 2016\n",
    "finm = 8\n",
    "find = 10\n",
    "#download: geopotential height, u and v climatology for the selected period\n",
    "#          geopotential height anomalies\n",
    "\n",
    "variables = ['Zonal+Wind','Meridional+Wind','Geopotential+Height']\n",
    "\n",
    "out_var = ['zonalw_climo','meridw_climo','hgt_climo','hgt']\n",
    "\n",
    "for i in range(0,3):\n",
    "    if i==2: # download climo and anomaly for geopotential\n",
    "        descarga_nc(inim,inid,finm,find,finy,variables[i],out_var[i],3)\n",
    "        descarga_nc(inim,inid,finm,find,finy,variables[i],out_var[i+1],2)\n",
    "    descarga_nc(inim,inid,finm,find,finy,variables[i],out_var[i],3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36,)\n",
      "(1, 36, 144)\n",
      "(1, 36, 144)\n",
      "(1, 36, 144)\n"
     ]
    }
   ],
   "source": [
    "# manipulation of netCDF files\n",
    "from netCDF4 import Dataset\n",
    "\n",
    "def manipular_nc(archivo,variable):\n",
    "    dataset = Dataset(archivo, 'r')\n",
    "    var_out = dataset.variables[variable][:]\n",
    "    lon = dataset.variables['lon'][:]\n",
    "    lat = dataset.variables['lat'][:]\n",
    "    dataset.close()\n",
    "    return var_out, lon, lat\n",
    "\n",
    "ruta = \"./tmp/\"\n",
    "\n",
    "out_var = ['zonalw_climo','meridw_climo','hgt_climo','hgt']\n",
    "\n",
    "nc_var = ['uwnd','vwnd','hgt']\n",
    "\n",
    "[uclm,lon,lat] = manipular_nc(ruta+out_var[0]+'.nc',nc_var[0])\n",
    "\n",
    "[vclm,lon,lat] = manipular_nc(ruta+out_var[1]+'.nc',nc_var[1])\n",
    "\n",
    "[zclm,lon,lat] = manipular_nc(ruta+out_var[2]+'.nc',nc_var[2])\n",
    "\n",
    "[zaa,lon,lat] = manipular_nc(ruta+out_var[3]+'.nc',nc_var[2])  #zaa [1 nlat nlon]\n",
    "\n",
    "#restringe domain to latitudes south to 0\n",
    "index_lat = np.where(lat<0)\n",
    "zaa = zaa[0,index_lat,:]\n",
    "lat = lat[index_lat]\n",
    "uclm = uclm[0,index_lat,:]\n",
    "vclm = vclm[0,index_lat,:]\n",
    "\n",
    "#print(range(index_lat))\n",
    "print(lat.shape)\n",
    "print(zaa.shape)\n",
    "print(uclm.shape)\n",
    "print(vclm.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#computation of plum fluxes. Script adapted from Kazuaki Nishii and Hisashi Nakamura\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def c_diff(arr, h, dim, cyclic = False):  #compute derivate of array variable respect to h associated to dim\n",
    "    #adapted from kuchaale scrip\n",
    "    ndim = arr.ndim\n",
    "    lst = [i for i in range(ndim)]\n",
    "\n",
    "    lst[dim], lst[0] = lst[0], lst[dim]\n",
    "    rank = lst \n",
    "    arr = np.transpose(arr, tuple(rank))\n",
    "\n",
    "    if ndim == 3:\n",
    "        shp = (arr.shape[0]-2,1,1)\n",
    "    elif ndim == 4:\n",
    "        shp = (arr.shape[0]-2,1,1,1)\n",
    "    \n",
    "    d_arr = np.copy(arr)\n",
    "    if not cyclic:  \n",
    "        d_arr[0,...] = (arr[1,...]-arr[0,...])/(h[1]-h[0])\n",
    "        d_arr[-1,...] = (arr[-1,...]-arr[-2,...])/(h[-1]-h[-2])\n",
    "        d_arr[1:-1,...] = (arr[2:,...]-arr[0:-2,...])/np.reshape(h[2:]-h[0:-2], shp)\n",
    "\n",
    "    elif cyclic:\n",
    "        d_arr[0,...] = (arr[1,...]-arr[-1,...])/(h[1]-h[-1])\n",
    "        d_arr[-1,...] = (arr[0,...]-arr[-2,...])/(h[0]-h[-2])\n",
    "        d_arr[1:-1,...] = (arr[2:,...]-arr[0:-2,...])/np.reshape(h[2:]-h[0:-2], shp)\n",
    "\n",
    "    d_arr = np.transpose(d_arr, tuple(rank))\n",
    "\n",
    "    return d_arr\n",
    "\n",
    "[xxx,nlats,nlons] = zaa.shape\n",
    "\n",
    "#gas constant\n",
    "Ra = 290\n",
    "\n",
    "#earth radius\n",
    "a = 6400000\n",
    "\n",
    "coslat = np.cos(lat*3.14/180)\n",
    "sinlat = np.sin(lat*3.14/180)\n",
    "\n",
    "#Coriolis parameter\n",
    "f = 2*7.24/100000*sinlat\n",
    "f0 = 2*7.24/100000*math.sin(43*3.14/180)\n",
    "\n",
    "#gravity\n",
    "g = 9.8\n",
    "\n",
    "# unit [Pa]\n",
    "lev = 20000\n",
    "\n",
    "# basic state (climatology): uclm vclm zclm\n",
    "\n",
    "# anomalies zaa\n",
    "\n",
    "# QG stream function\n",
    "psiaa = g/np.transpose(np.tile(f,(nlons,1)))*zaa\n",
    "\n",
    "# magnitude of basic state wind speed\n",
    "magU = np.sqrt(np.add(np.power(uclm,2),np.power(vclm,2)))\n",
    "\n",
    "#psi derivatives\n",
    "dpsidlon = c_diff(psiaa,lon,2)\n",
    "ddpsidlonlon = c_diff(dpsidlon,lon,2)\n",
    "\n",
    "dpsidlat = c_diff(psiaa,lat,1)\n",
    "ddpsidlatlat = c_diff(dpsidlat,lat,1)\n",
    "ddpsidlatlon = c_diff(dpsidlat,lon,2)\n",
    "\n",
    "termxu = dpsidlon*dpsidlon-psiaa*ddpsidlonlon\n",
    "\n",
    "termxv = dpsidlon*dpsidlat-ddpsidlatlon*psiaa\n",
    "\n",
    "termyv = dpsidlat*dpsidlat-psiaa*ddpsidlatlat\n",
    "\n",
    "# \"p\" is normalized by 1000hPa\n",
    "coeff1=np.transpose(np.tile(coslat,(nlons,1)))*(lev/100000)/(2*magU)\n",
    "#x-component\n",
    "\n",
    "px = coeff1/(a*a*np.transpose(np.tile(coslat,(nlons,1))))*( uclm*termxu/np.transpose(np.tile(coslat,(nlons,1))) + vclm*termxv)\n",
    "\n",
    "#y-component\n",
    "\n",
    "py = coeff1/(a*a)*( uclm/np.transpose(np.tile(coslat,(nlons,1)))*termxv + vclm*termyv)\n",
    "\n",
    "#set lon 0 360\n",
    "\n",
    "#set gxout contour\n",
    "#set cint 30\n",
    "#set black -0.1 0.1\n",
    "\n",
    "#* stream-function-like geopotential height\n",
    "#d maskout( zaa*abs(f0/f),  abs(lat)-10)\n",
    "\n",
    "#* horizontal wave-activity flux\n",
    "#set arrscl 0.5 20\n",
    "#d skip(px,6,4);maskout( py , abs(lat)-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5184)\n",
      "(1, 36, 144)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36,)\n",
      "(1, 36, 144)\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
